---
title: "Estimable Functions"
author: "Peter von Rohr"
format: beamer
---

## Estimable Functions

```{r ex-estimable-function-data, echo=FALSE}
n_nr_rec_est_fun <- 6
tbl_est_fun <- tibble::tibble(Animal = c(1:n_nr_rec_est_fun),
                              Breed  = c(rep("Angus", 3), "Limousin", rep("Simmental", 2)),
                              Observation = c(16, 10, 19, 27, 11, 13))

knitr::kable(tbl_est_fun,
             booktabs = TRUE,
             longtable = FALSE,
             escape = FALSE)
```


## Model

$$\mathbf{y} = \mathbf{Xb} + \mathbf{e}$$

```{r, echo=FALSE, results='asis'}
# design matrix X
mat_x_est_fun <- model.matrix(lm(Observation ~ 0 + Breed, data = tbl_est_fun))
attr(mat_x_est_fun, "assign") <- NULL
attr(mat_x_est_fun, "contrasts") <- NULL
colnames(mat_x_est_fun) <- NULL
mat_x_est_fun <- cbind(matrix(rep(1, nrow(mat_x_est_fun)), ncol = 1), mat_x_est_fun)
# parameter vector b
vec_b <- c("\\mu", "\\alpha_1", "\\alpha_2", "\\alpha_3")
cat("$$\n")
cat(paste0(rmdhelp::bcolumn_vector(pvec = tbl_est_fun$Observation, ps_name = "\\mathbf{y}"), collapse = '\n'))
cat("\\text{, }")
cat(paste0(rmdhelp::bmatrix(pmat = mat_x_est_fun, ps_name = "\\mathbf{X}"), collapse = "\n"))
cat("\\text{ and }")
cat(paste0(rmdhelp::bcolumn_vector(pvec = vec_b, ps_name =  "\\mathbf{b}"), collapse = "\n"), "\n")
cat("$$\n")
```


## Normal Equations

$$ X^TXb^{(0)} = X^Ty$$

```{r, echo=FALSE, results='asis'}
mat_xtx_est_fun <- crossprod(mat_x_est_fun)
mat_xty_est_fun <- crossprod(mat_x_est_fun, tbl_est_fun$Observation)
vec_b0 <- c("\\mu^0", "\\alpha_1^0", "\\alpha_2^0", "\\alpha_3^0")
cat("$$\n")
cat(paste0(rmdhelp::bmatrix(mat_xtx_est_fun), collapse = '\n'))
cat(paste0(rmdhelp::bcolumn_vector(pvec = vec_b0), collapse = '\n'))
cat(" = ")
cat(paste0(rmdhelp::bmatrix(pmat = mat_xty_est_fun), collapse = '\n'))
cat("$$\n")
```

A solution

```{r, echo=FALSE, results='asis'}
mat_b_sol <- crossprod(MASS::ginv(mat_xtx_est_fun), mat_xty_est_fun)
cat(paste0(rmdhelp::bmatrix(round(mat_b_sol, digits = 1), ps_name = "b^{(0)}", ps_env = "$$"), collapse = '\n'))

```


## Solutions to Normal Equations

```{r, echo=FALSE}
# verify given solutions
mat_b_sol_given <- matrix(c(16, -1, 11, -4, 14, 1, 13, -2, 27, -12, 0, -15,-2982, 2997, 3009, 2994), ncol = 4)
#crossprod(t(mat_x_est_fun), mat_b_sol_given)
#mat_xty_est_fun
# generate some random solutions
set.seed(0408)
n_nr_sol <- 4
n_nr_eqs <- nrow(mat_xtx_est_fun)
mat_Z <- matrix(c(rep(1, n_nr_sol),
                  1:n_nr_sol,
                  sample(10, n_nr_sol),
                  3000 + sample(20, n_nr_sol)), nrow = n_nr_eqs)
# solutions based on MASS::ginv
mat_xtx_ginv <- MASS::ginv(mat_xtx_est_fun)
mat_sol <- crossprod(mat_xtx_ginv, mat_xty_est_fun)
mat_B0 <- matrix(data = c(rep(mat_sol, n_nr_sol)), ncol = n_nr_sol)
# additional solutions
mat_B_tilde <- mat_B0 + (crossprod(mat_xtx_ginv, mat_xtx_est_fun) - diag(nrow = n_nr_sol)) %*% mat_Z

```

```{r est-fun-sol, echo=FALSE}
tbl_est_fun_sol <- tibble::tibble(`Elements of Solution` = c("$\\mu^0$", "$\\alpha_1^0$", "$\\alpha_2^0$", "$\\alpha_3^0$"),
                                  `$b_1^0$` = mat_B_tilde[,1],
                                  `$b_2^0$` = mat_B_tilde[,2],
                                  `$b_3^0$` = mat_B_tilde[,3],
                                  `$b_4^0$` = mat_B_tilde[,4])
knitr::kable(tbl_est_fun_sol,
             booktabs = TRUE,
             longtable = FALSE,
             escape = FALSE)
```


## Functions of Solutions

```{r lin-fun-sol, echo=FALSE}
tbl_lin_fun_sol <- tibble::tibble(`Linear Function` = c("$\\alpha_1^0 - \\alpha_2^0$", "$\\mu^0 + \\alpha_1^0$", "$\\mu^0 + 1/2(\\alpha_2^0 + \\alpha_3^0)$"),
                                  `$b_1^0$` = c(mat_B_tilde[2,1] - mat_B_tilde[3,1], 
                                                mat_B_tilde[1,1] + mat_B_tilde[2,1], 
                                                mat_B_tilde[1,1] + 0.5*(mat_B_tilde[3,1]+mat_B_tilde[4,1])),
                                  `$b_2^0$` = c(mat_B_tilde[2,2] - mat_B_tilde[3,2], 
                                                mat_B_tilde[1,2] + mat_B_tilde[2,2], 
                                                mat_B_tilde[1,2] + 0.5*(mat_B_tilde[3,2]+mat_B_tilde[4,2])),
                                  `$b_3^0$` = c(mat_B_tilde[2,3] - mat_B_tilde[3,3], 
                                                mat_B_tilde[1,3] + mat_B_tilde[2,3], 
                                                mat_B_tilde[1,3] + 0.5*(mat_B_tilde[3,3]+mat_B_tilde[4,3])),
                                  `$b_4^0$` = c(mat_B_tilde[2,4] - mat_B_tilde[3,4], 
                                                mat_B_tilde[1,4] + mat_B_tilde[2,4], 
                                                mat_B_tilde[1,4] + 0.5*(mat_B_tilde[3,4]+mat_B_tilde[4,4])))
knitr::kable(tbl_lin_fun_sol,
             booktabs = TRUE,
             longtable = FALSE,
             escape = FALSE)
```

* $\alpha_1^0 - \alpha_2^0$: estimate of the difference between breed effects for Angus and Simmental
* $\mu^0 + \alpha_1^0$: estimate of the general mean plus the breed effect of Angus
* $\mu^0 + 1/2(\alpha_2^0 + \alpha_3^0)$: estimate of the general mean plus mean effect of breeds Simmental and Limousin


## Definition of Estimable Functions 

$$\mathbf{q}^T\mathbf{b} = \mathbf{t}^TE(\mathbf{y})$$

* Why is $\mathbf{q}^T\mathbf{b}$ estimable? $\rightarrow$ invariance to solution $b^{(0)}$
 
$$\mathbf{q}^T\mathbf{b}^{(0)} = \mathbf{t}^TE(\mathbf{y}) = \mathbf{t}^T X\mathbf{b}^{(0)} = \mathbf{t}^T XGX^Ty$$
where $\mathbf{XGX}^T$ is the same for all choices of $\mathbf{G}$


## Examples

$$E(y_{1j} - y_{2j}) = \alpha_1 - \alpha_2$$
with $\mathbf{t}^T = \left[\begin{array}{cccccc}  1 & 1 & 1 & -1 & 0 & 0 \end{array}\right]$ and $\mathbf{q}^T = \left[\begin{array}{cccc} 0 & 1 & -1 & 0 \end{array} \right]$

$$E(y_{1j}) = \mu + \alpha_1$$

$$E(y_{2j}) = \mu + \alpha_2$$

$$E(y_{3j}) = \mu + \alpha_3$$

## Property

Based on the definition, the following property can be derived

$$\mathbf{q}^t = \mathbf{t}^T\mathbf{X}$$
with the definition of an estimable function $\mathbf{q}^T\mathbf{b}$, we get 

$$\mathbf{q}^T\mathbf{b} = \mathbf{t}^TE(\mathbf{y})$$
$$\mathbf{q}^T\mathbf{G}\mathbf{X}^T\mathbf{y} = \mathbf{t}^T\mathbf{X}\mathbf{G}\mathbf{X}^T\mathbf{y}$$
hence for any $\mathbf{G}$, $\mathbf{q}^t = \mathbf{t}^T\mathbf{X}$ which is helpful to find $\mathbf{q}$ for a given $\mathbf{t}$


## Test

When we want to test whether a certain vector $\mathbf{q}$ can establish an estimable function, we can test wheter

$$\mathbf{q}^T\mathbf{H} = \mathbf{q}^T$$

with $\mathbf{H} = \mathbf{GX}^T\mathbf{X}$

Setting $\mathbf{q}^T = \mathbf{t}^T\mathbf{X}$, we get 

$$\mathbf{q}^T\mathbf{H} = \mathbf{t}^T\mathbf{X}\mathbf{H} = \mathbf{t}^T\mathbf{X} =  \mathbf{q}^T $$


